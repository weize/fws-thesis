\chapter{Conclusions and Future Work}
\label{ch:conclusions}
\section{Conclusions}
In this thesis, we investigated Faceted Web Search, an extension of faceted search in the open-domain web setting. We studied three fundamental problems in Faceted Web Search, namely (1) how to automatically generate facets, (2) how to re-organize search results with user feedback on facets and (3) how to evaluate generated facets and entire systems. To address these problems, we have: (1) developed query facet extraction for automatic facet generation; (2) developed an intrinsic evaluation method for evaluating generated facets; (3) developed an empirical utility maximization approach and a selective query faceting method for improving query facet extraction in precision-oriented scenarios; (4) investigated both boolean filtering and soft ranking models for facet feedback; (5) developed an extrinsic evaluation method that evaluate entire systems in terms of their utility and cost in assisting search.

In Chapter~\ref{ch:facet}, we developed query facet extraction, which extracts facets for a given query from its search results. Changing from a global approach that generates facets in advance for an entire corpus~\cite{stoica2007automating,dakka2008automatic} to a query-based approach, query facet extraction provides a promising direction for solving facet generation in Faceted Web Search.
By focusing on the search results, query facet extraction avoids dealing with the entire web, which is large and heterogeneous. By directly generating facets for queries, it also addresses the facet recommendation problem at the same time.
 
For query facet extraction, we developed a supervised approach based on a graphical model to recognize facets from the noisy candidates found. The graphical model learns how likely a candidate term is to be a facet term as well as how likely two terms are to be grouped together in a query facet, and captures the dependencies between the two factors. We proposed two algorithms (\QFI and \QFJ) for approximate inference on the graphical model since exact inference is intractable. Compared with other existing methods, our models can easily incorporate a rich set of features, and learn for available labeled data.

In Chapter~\ref{ch:intrinsiceval}, we developed an intrinsic evaluation method that evaluates generated facets by comparing them with human-created ones. We described how to collect human annotations for query facets by a pooling method. We designed \PRF, an evaluation measure that combines precision and recall of facet terms with grouping quality, using weighted harmonic mean. The measure can adjust emphasis between the three factors for different application scenarios. Experimental results based on this intrinsic evaluation show that our supervised method (\QFI and \QFJ), can take advantage of a richer set of features and outperforms other unsupervised methods.

In Chapter~\ref{ch:precision}, we investigated query facet extraction models under precision-oriented scenarios, and improved our models in such scenarios. The precision-oriented scenarios consider a more practical setting, in which users care more about precision of presented facets than recall. From the investigation, we found that our model (\QFJ) optimized based on likelihood fails to adapt to the precision oriented scenarios, suggesting likelihood could be loosely related to the performance measure in such scenarios. Thus, we developed an empirical utility maximization approach to optimize the performance measure instead of likelihood. However, exact optimization on the performance measure is difficult due to the non-continuous and non-differentiable nature of the objective. We solved this problem by approximating the performance measure using its expectation. Our experiments show that this empirical utility maximization approach significantly improves our query facet model (\QFJ) under precision-oriented scenarios, suggesting utility is a better learning objective than likelihood, and our expectation-based approximation is effective. 
 
Besides empirical utility maximization, we also improved query facet extraction performance in the precision-oriented scenarios by selective query faceting. In our investigation, We found query facet extraction quality varies drastically from excellent to poor and completely noisy. In the precision-oriented scenario, it may be more desirable to avoid showing facets for those poor performing queries and leave the users with a clean keyword-search interface. Thus, we proposed selective query faceting to show facets for good performing queries and avoid poor performing ones. A key problem, however, is how to predict the extraction performance. To solve the problem, we proposed PRF score based on the expectation of \PRF to predict the performance. We show this score has fairly good prediction performance which enables selective query faceting, and improves the performance for the selected queries with fair coverage over the entire query traffic.

In Chapter~\ref{ch:feedback}, we investigated both Boolean filtering and soft ranking models for facet feedback. The Boolean filtering models filter the search results based on users' selection on facets, which is the dominant feedback model in conventional faceted search. Instead, soft ranking models re-ranks the documents by expanding the original query with selected terms in facets. Our experiments (in Chapter~\ref{ch:extrinsiceval}) show that the Boolean filtering models are too strict in Faceted Web Search, and less effective than soft ranking models.

In Chapter~\ref{ch:extrinsiceval}, we developed our extrinsic evaluation method that evaluates entire Faceted Web Search systems in terms of their utility in assisting search in an interactive search task. In the search task, a user searches an under-specified query, the FWS system provides query facets from which the user can select terms in the facets that would help further specified the query, after which the FWS system uses the feedback terms for re-ranking documents. Our extrinsic evaluation considers both gain in terms of the re-ranking performance and cost in terms of the time users spend for selecting feedback terms. The re-ranking gain can be measured by standard IR metrics like MAP or nDCG. The time cost ideally can be exactly measured by carrying out user studies. 

However, we noticed the user-study-based time measurement would make the evaluation difficult and expensive to extend for evaluating new systems rapidly. Thus, we proposed to simulate the user feedback process based on a user interaction model, using oracle feedback terms and feedback terms collected from human annotators. Both the oracle feedback and annotator feedback incrementally select all feedback terms that a user may select, which will then be used in simulation based on the user model to determine which subset of facet terms are selected by a user and how much time is spent giving that feedback. We also describe a way to build reusable test collection for the extrinsic evaluation, and make our collected data set publicly available\footnote{See http://ciir.cs.umass.edu/downloads}.

Our experiments show, by using facet feedback from human annotator, Faceted Web Search is able to assist the search task and significantly improve ranking performance if allowed sufficient time for user feedback: 18.0\% in NDCG@10 if we allow users to examine 50 terms in facets, and 7.4\% in NDCG@10 if we allow time for examining 10 terms. Comparing intrinsic evaluation and extrinsic evaluation on different facet generation models, we found that the intrinsic evaluation does not always reflect system utility in real application. Comparing different facet feedback models, as mentioned earlier, we found that the Boolean filtering models are too strict in Faceted Web Search, and less effective than soft ranking models.

\section{Future Work}
As a first extensive attempt for extending faceted search to the open-domain web, this work has some limitations, but also opens up many interesting directions for future work.


% query facet with labels, or high-level taxonomies as two or more level taxonomies in
In this work, a query facet is defined as a set of coordinate terms (\eg, \{\concept{AA}, \concept{JetBlue}, \concept{Delta}\}), but with no label (\eg, \concept{airlines}) for the set . This facet representation corresponds to one-level faceted taxonomies, in which information objects that belong to a same parent node are shown as a facet. However, explicitly showing labels for each query facets, or equivalently showing two-level faceted taxonomies, would be more desirable, as facet labels could help users quickly comprehend each query facets. There are two potential directions for solving this facet labeling problems. First, we could resort to some extraction patterns that extract facet candidates together with their labels.
For example, from the sentence \concept{... \underline{airline} such as AA, Delta, and JetBlue.}, based on the pattern ``\textit{\underline{NP}} such as \textit{NP}, \textit{NP}, ..., and \textit{NP}'', we can extract facet candidate \{\concept{AA}, \concept{Delt}, \concept{JetBlue}\} together with the label \concept{airlines}. After candidate extraction, we need models for refining candidate facets with labels, which is also a very interesting problem. Second, we can resort to existing taxonomies. We can classify extracted query facets in to the taxonomies (\eg, assign \concept{AA}, \concept{Delt}, \concept{JetBlue} as child nodes for node \concept{airlines} in the taxonomy), and then use the assigned parent nodes as labels. One problem with this direction is that existing taxonomies created may have difficulties in covering all query facets web search users are interested in. 

% ranking facets
In Chapter~\ref{ch:facet}, we used a heuristic score for ranking extracted query facets. The score is defined as $score(F)=\sum_{t \in F}{P(t)}$, which sums up the probabilities of each terms $t$ being facet terms, in order to present more facet terms in top. This ranking model might be far from optimal, and there are other ranking models that could potentially improve facet ranking performance. For example, learning-to-rank models~\cite{liu2009learning} has been well-studied, and according to their previous success in information retrieval, it may also work for query facet ranking. However, one problem with using learning to rank is that we need to design informative features that measures the quality of a extracted query facet.

% other resources for extracting query facets or features for improving extraction performance
In this work, we focused on extracting query facet from search results. However, a variety of other resources can be useful for query facet extraction. For example, existing taxonomies or knowledge bases (\eg, Freebase\footnote{www.freebase.com}) can be useful for extracting candidate facets. Ideally, we can identify concepts (or entities) in a taxonomy that are relevant to the query, and then use the concepts with their child nodes as facet candidates (or query facets directly). For example, if we find concept \concept{airline} is relevant to our query \concept{baggage allowance}, and the taxonomy contains a node for \concept{airline}, then we can use the concept's child nodes (\concept{AA}, \concept{Delta}, \concept{JetBlue}) as facet candidates. We can also design features base on taxonomies to improve our models, such as the feature \concept{if two terms are assigned to a same parent node in a taxonomy}. Besides taxonomies or knowledge bases, query logs can also be helpful. They can be used to extract features to measure how useful and important facet terms or query facets are, and potentially improve term ranking within query facets, or facet ranking. For example, there may be many airlines extracted in the airline facet, based on statistics in query logs, we can easily find which airlines are more popular and rank them ahead in the query fact.

% optimizing utility in inferencing
In Chapter~\ref{ch:precision}, to improve the performance in precision-oriented scenarios, we used an empirical utility maximization approach that optimize the performance measure for training our query faceting models. However, we haven't investigated  decision theoretic approaches, advocated by \citet{lewis1995evaluating}, which try to optimize the performance measure during inferencing. \citet{nan2012optimizing} compared both two approaches for optimizing F-Measures. Their results suggest that the two approaches are asymptotically equivalent given large training and test sets. Nevertheless, empirically, the empirical utility maximization approach appears to be more robust against model misspecification, and given a good model, the decision-theoretic approach appears to be better for handling rare classes and a common domain adaptation scenario. It would be interesting to also develop an decision theoretic approach for optimizing \PRF measure, and compare with our proposed empirical utility maximization approach.


% extrinsic evaluation user models
Lastly, in Chapter~\ref{ch:extrinsiceval}, we used a simple user interaction model based on some strong assumptions that may not hold in real scenarios. For example, in the user model, we originally model the time a user spend for scanning a facet $F$ as $T(F)$. However, to simplify the estimation, we assume time costs are equal for scanning different facets (\ie, $T(F)=T_f$, where $T_f$ is a constant). In facet, the time a user spend for scanning a facet is highly dependent on the facet quality. Users may spend much more time for low-quality facets, in order to figure out what the facets are about. For example, the extracted facet \{\concept{AA}, \concept{first}, \concept{Delta}, \concept{business}, \concept{JetBlue}\} mixes facet \concept{airline} and facet \concept{flight classes} together. When a user encounters this facet, he or she may be confused and take more time in scanning.
To improve time estimation, we could model the time cost based on the facet quality.








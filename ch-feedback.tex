\chapter{Facet Feedback}
\label{ch:feedback}
\section{Introduction}
\label{sec:fdbk-intro}
\textbf{Facet feedback}~\cite{kong2014extending} is to adjust (filter or re-rank) the search results based on users' selections on the provided facets (corresponding to step 5 in Figure~\ref{fig:fws-example}). Boolean filtering, which filters search results by requiring selected terms to appear, is the dominant facet feedback method used in conventional faceted search. However, it may be too strict when extended to the open-domain setting. Boolean filtering is based on two assumptions~\cite{zhang2010interactive}: (1) users are clear about what they are looking for, and thus are able to select proper terms to restrict the results; and (2) matching between a term and a document is accurate and complete. In FWS, that means a document that contains the selected term should be relevant to the term, and all documents relevant to that selected term should contain the term. Neither of the two assumptions are likely to hold in FWS.
Therefore, we propose soft ranking models that expand original queries with user selected terms for re-ranking.

In this chapter we describe the two types of models we explore for facet feedback: Boolean filtering and soft ranking. We will first define notations used in facet feedback models in Section~\ref{sec:fdbk-notations}, and then present Boolean filtering and soft ranking models in Section~\ref{sec:fdbk-filter} and Section~\ref{sec:fdbk-ranking} respectively.  We will explore the effectiveness of these approaches in Chapter~\ref{ch:extrinsiceval}. 
%The work in this chapter is completed and published~\cite{kong2014extending}.

\section{Related Work}
\label{sec:feedback-related}
There is a long history of using user explicit feedback to improve retrieval performance. In relevance feedback~\cite{rocchio71relevance,salton1997improving}, documents are presented to users for judgment, after which terms are extracted from the judged relevant document, and added into the retrieval model. In the case where true relevance judgment is unavailable, top documents are assumed to be relevant, which is called pseudo relevance feedback~\cite{buckley1995automatic,abdul2004umass}. Because document is a large text unit, which can be difficult for users to judge and for the system to incorporate relevance information, previous work also studied user feedback on passages~\cite{allan1995relevance,xu1996query} and terms~\cite{koenemann1996case,tan2007term}. For faceted search, \citet{zhang2010interactive} study user feedback on facets, using both boolean filtering and soft ranking models. However, the study is based on corpora with human created facet metadata, which is difficult to 
obtain for the  general web.  One other difference between our work and most other user feedback work is that facet feedback in our work is used to improve ranking with respect to the query subtopic specified by the feedback terms, instead of the query topic represented by the original query. This presents the scenario in FWS, where users start with a less-specified query, and then use facets to help clarify and search for subtopic information.

\section{Notations} \label{sec:fdbk-notations}
We use $t^u$ to denote a \textbf{feedback term} selected by a user $u$, $F^u=\{t^u\}$ to denote a facet that contains feedback terms (a \textbf{feedback facet}), and $\mathcal{F}^u=\{F^u\}$ to denote the set of feedback facets. Given those, a feedback model can be formally denoted as $S'(D,Q,\mathcal{F}^u)$, which gives a score for document $D$ according to the original query $Q$ and the user's feedback $\mathcal{F}^u$. 

\section{Boolean Filtering Model} \label{sec:fdbk-filter}
The Boolean model filters documents based on Boolean operations using the feedback $\mathcal{F}^u$. Similar to \citet{zhang2010interactive}, we study three different Boolean conditions for filtering. We use the AND condition to require that the document contains \emph{all} of the feedback terms in $\mathcal{F}^u$. The AND condition might be too strict, so a relaxed alternative is to use the OR condition, which requires that the document contains \emph{at least one} of the feedback terms. The last Boolean condition, A+O, is somewhere in between the two conditions above. It use AND across different feedback facets in $\mathcal{F}^u$, and OR for terms $t^u$ inside each facet $F^u$. The Boolean feedback model scores a document by
\begin{equation}
S_{B}'(D,Q,\mathcal{F}^u) = \left\{ \begin{array}{ll}
S(D,Q) &\mbox{ if $D$ satisfies condition $B(\mathcal{F}^u)$} \\
-\infty &\mbox{ otherwise}
\end{array} \right.
\end{equation}
where condition $B$ can be either AND, OR, or A+O, and $S(D,Q)$ is the score returned by the original retrieval model. Notice that when there is only a single feedback term, the three conditions will be equivalent; when there is only one feedback query facet (group of feedback terms), OR and A+O will be equivalent.

\section{Soft Ranking Model} \label{sec:fdbk-ranking}
While Boolean filter models are commonly used in faceted search, it may be too strict for FWS, as explained in Section~\ref{sec:fdbk-intro}. %The Boolean filtering model is based on two assumptions~\cite{zhang2010interactive}: (1) users are clear about what they are looking for, and thus are able to select proper feedback terms to restrict the results; and (2) matching between a facet term and a document is accurate and complete. In FWS, that means a document that contains the feedback term should be relevant to the term, and all documents relevant to that feedback term should contain the term. However, both of the two assumptions are unlikely to hold in FWS.
Therefore, we also use soft ranking models, which expand the original query with feedback terms, using a linear combination as follows
\begin{equation}
 S_E'(D,Q,\mathcal{F}^u) = \lambda S(D,Q) + (1-\lambda) S_E(D,\mathcal{F}^u)
\end{equation}
where $S(D,Q)$ is the score from the original retrieval model as before, and $S_E(D,\mathcal{F}^u)$ is the expansion part which captures the relevance between the document $D$ and feedback facet $\mathcal{F}^u$, using expansion model $E$. $\lambda$ is a parameter for adjusting the weight between the two parts.

We use two expansion models, a term and a facet expansion model. The term expansion model, $ST$, assigns equal weight for all the feedback terms, as follow,
\begin{equation}
S_{ST}(D,\mathcal{F}^u) = \frac{1}{N}\sum_{F^u\in\mathcal{F}^u}{\sum_{t^u\in F^u}{S(D,t^u)}}
\end{equation}
where $N$ is the total number of facet terms. $S(D,t^u)$ can be the original retrieval model used for the query or a different model.

The facet expansion model, $SF$, uses the facet structure information. It assigns equal weights between each feedback facets, and equal weights between feedback terms within the same facet, as shown below.
\begin{equation}
S_{SF}(D,\mathcal{F}^u) = \frac{1}{|\mathcal{F}^u|} \sum_{F^u \in \mathcal{F}^u}{ \frac{1}{|F^u|} \sum_{t^u \in F^u}{S(D, t^u)}}
\end{equation}

Notice that the two expansion models will be equivalent when there is only a single feedback term or when there is only one feedback facet. In our experiments, we use the Sequential Dependence Model (SDM)~\cite{metzler2005markov} as the baseline retrieval model $S(D,Q)$, which incorporates word unigrams, adjacent word bigrams, and adjacent word proximity. For $S(D,t^u)$, we use the Query Likelihood model with Dirichlet smoothing as below,
\begin{equation}
S(D,t^u)=\sum_{w\in t^u}{\log\frac{tf(w,D)+\mu\frac{tf(w,\mathcal{C})}{|\mathcal{C}|}}{|D|+\mu}}
\end{equation}
where $w$ is a word in $t^u$, $tf(w,D)$ and $tf(w,\mathcal{C})$ are the number of occurrences of $w$ in the document and the collection respectively; $\mu$ is the Dirichlet smoothing parameter; $|D|$ is the number of word in $|D|$, and $|\mathcal{C}|$ is the total number of words in the collection.

\section{Summary}
In this chapter, we described three Boolean filtering models (AND, OR, A+O) and proposed two soft ranking models (ST and SF) for facet feedback. In the next chapter, we will develop an extrinsic evaluation method for evaluating these feedback models.